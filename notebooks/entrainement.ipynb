{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "91908d63",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.19.1)\n",
            "Requirement already satisfied: onnxscript in /usr/local/lib/python3.12/dist-packages (0.5.6)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Requirement already satisfied: onnx_ir<2,>=0.1.12 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.1.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install onnx onnxscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "275dec9b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando en: cuda\n",
            "Epoca 1 [0/60000] Loss: 2.2935\n",
            "Epoca 1 [6400/60000] Loss: 0.2782\n",
            "Epoca 1 [12800/60000] Loss: 0.1545\n",
            "Epoca 1 [19200/60000] Loss: 0.0409\n",
            "Epoca 1 [25600/60000] Loss: 0.0769\n",
            "Epoca 1 [32000/60000] Loss: 0.0504\n",
            "Epoca 1 [38400/60000] Loss: 0.0101\n",
            "Epoca 1 [44800/60000] Loss: 0.0078\n",
            "Epoca 1 [51200/60000] Loss: 0.0198\n",
            "Epoca 1 [57600/60000] Loss: 0.0559\n",
            "Epoca 2 [0/60000] Loss: 0.0657\n",
            "Epoca 2 [6400/60000] Loss: 0.0812\n",
            "Epoca 2 [12800/60000] Loss: 0.0696\n",
            "Epoca 2 [19200/60000] Loss: 0.1320\n",
            "Epoca 2 [25600/60000] Loss: 0.1256\n",
            "Epoca 2 [32000/60000] Loss: 0.0069\n",
            "Epoca 2 [38400/60000] Loss: 0.0911\n",
            "Epoca 2 [44800/60000] Loss: 0.0182\n",
            "Epoca 2 [51200/60000] Loss: 0.0150\n",
            "Epoca 2 [57600/60000] Loss: 0.0405\n",
            "\n",
            "Precision en Test set: 98.82%\n",
            "\n",
            "Exportando a ONNX...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3423498066.py:93: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(model,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.onnx] Obtain model graph for `SimpleCNN([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `SimpleCNN([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 1 of general pattern rewrite rules.\n",
            "Modelo guardado como 'mnist_cnn.onnx'\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e2b540c2-6895-4de1-a89b-c0d3d9323c37\", \"mnist_cnn.onnx\", 11990)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# 1. Configuración y Carga de Datos (Batch size ayuda a la velocidad)\n",
        "BATCH_SIZE = 64\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) # Normalización estándar de MNIST\n",
        "])\n",
        "\n",
        "# Descarga y carga automática (mucho más limpio que fetch_openml a mano)\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False, num_workers=0)\n",
        "\n",
        "# 2. Definir la Arquitectura (CNN Simple)\n",
        "# Esto reemplaza a HOG. La red aprende a buscar bordes y formas.\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # Capa convolucional: Extrae características (como HOG pero automático)\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        # Capas lineales: Clasificación (como tu SVM/DecisionTree)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10) # 10 dígitos de salida\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x es la imagen cruda [Batch, 1, 28, 28]\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2) # Reduce tamaño a 14x14\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2) # Reduce tamaño a 7x7\n",
        "        \n",
        "        x = torch.flatten(x, 1) # Aplanar para la parte densa\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x # Devuelve logits (sin softmax, CrossEntropyLoss lo maneja)\n",
        "\n",
        "# 3. Entrenamiento (Train loop)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"Entrenando en: {device}\")\n",
        "\n",
        "def train(epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoca {epoch+1} [{batch_idx * len(data)}/{len(train_loader.dataset)}] Loss: {loss.item():.4f}')\n",
        "\n",
        "# 4. Evaluación\n",
        "def test():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    print(f'\\nPrecision en Test set: {acc:.2f}%')\n",
        "\n",
        "# Ejecutar\n",
        "train(epochs=2) # Con 2 épocas basta para >98%\n",
        "test()\n",
        "\n",
        "# --- PASO CRUCIAL PARA MLOPS: EXPORTAR A ONNX ---\n",
        "print(\"\\nExportando a ONNX...\")\n",
        "dummy_input = torch.randn(1, 1, 28, 28, device=device) # Un ejemplo de entrada falsa\n",
        "torch.onnx.export(model, \n",
        "                  dummy_input, \n",
        "                  \"mnist_cnn.onnx\", \n",
        "                  input_names=['input'], \n",
        "                  output_names=['output'],\n",
        "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
        "print(\"Modelo guardado como 'mnist_cnn.onnx'\")\n",
        "\n",
        "files.download('mnist_cnn.onnx')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
